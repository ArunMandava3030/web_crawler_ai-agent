Perfect, thanks for pasting the full one. I see what you want:
Weâ€™ll polish it up so the README is more **professional, polished, and GitHub-ready** with:

* Cleaner formatting
* Proper image embedding (your screenshots will **display inline** instead of looking broken)
* A slightly improved workflow section
* Removal of duplicate/placeholder sections
* Extra clarity for someone who lands on your repo

Hereâ€™s the enhanced **README.md**:

---

````markdown
# ğŸ•·ï¸ AI Web Crawler + RAG Pipeline

This project is an **AI-powered web crawler and knowledge extraction pipeline**.  
It can **crawl websites**, extract clean text, **embed** it using **Qwen embeddings**, store the vectors in **ChromaDB**, and then use **Retrieval-Augmented Generation (RAG)** to answer user questions.  

It also ships with a **Streamlit frontend** where you can:  
âœ… Crawl and extract knowledge from any website  
âœ… Save structured knowledge as JSON  
âœ… Generate embeddings and store in a vector database  
âœ… Ask natural-language questions and get AI-powered answers  

---

## ğŸš€ Features

- ğŸŒ **Website Crawling** â†’ Powered by [Crawl4AI](https://github.com/unclecode/crawl4ai)  
- ğŸ“„ **Clean Text Extraction** â†’ Converts raw HTML into human-readable text  
- ğŸ§  **Embeddings with Qwen** â†’ Alibabaâ€™s Qwen embedding API  
- ğŸ—‚ï¸ **Vector Store with ChromaDB** â†’ Fast similarity search across crawled data  
- ğŸ” **RAG Question Answering** â†’ Combines retrieval with generative answers  
- ğŸ’¾ **Export JSON** â†’ Download extracted knowledge before embeddings  
- ğŸ–¥ï¸ **Streamlit UI** â†’ Easy-to-use interactive frontend  

---

## ğŸ“‚ Project Structure

```bash
project_root/
â”‚â”€â”€ scripts/
â”‚   â”œâ”€â”€ run_pipeline.py      # CLI pipeline runner
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ streamlit_app.py     # Streamlit frontend
â”‚â”€â”€ core/
â”‚   â”œâ”€â”€ crawler.py           # Crawl4AI-based crawler
â”‚   â”œâ”€â”€ embedder.py          # Qwen embedding functions
â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB vector store
â”‚   â”œâ”€â”€ rag.py               # Retrieval + QA logic
â”‚â”€â”€ outputs/
â”‚   â”œâ”€â”€ extracted_data.json  # Sample extracted JSON
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
````

---

## ğŸ”§ Installation

1. **Clone the repo**

   ```bash
   git clone https://github.com/your-username/ai-web-crawler-rag.git
   cd ai-web-crawler-rag
   ```

2. **Create virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate   # Mac/Linux
   venv\Scripts\activate      # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set environment variables**
   Create a `.env` file in the project root:

   ```ini
   QWEN_API_KEY=your_api_key_here
   ```

---

## â–¶ï¸ Usage

### 1. Run pipeline from CLI

Crawl a website, embed it, and store in ChromaDB:

```bash
python scripts/run_pipeline.py https://www.chrismytton.com/plain-text-websites/
```

ğŸ“¸ Example output:

![CLI Example](https://github.com/ArunMandava3030/web_crawler_ai-agent/blob/d4f92a6f761215adc197f3ee9db8e678106f1c51/Screenshot%202025-08-17%20110231.png)

---

### 2. Run Streamlit frontend

Launch the interactive dashboard:

```bash
streamlit run app/streamlit_app.py
```

ğŸ“¸ Streamlit UI:

![Streamlit Example](https://github.com/ArunMandava3030/web_crawler_ai-agent/blob/d4f92a6f761215adc197f3ee9db8e678106f1c51/Screenshot%202025-08-17%20110513.png)

---

## ğŸ§© Example Workflow

1. Enter a website URL in the Streamlit UI
2. Crawl + extract readable content
3. JSON output is generated (downloadable)
4. Embeddings are created using Qwen
5. ChromaDB stores vectors
6. Ask questions â†’ AI answers with RAG

---

## âš¡ Tech Stack

* [Python 3.10+](https://www.python.org/)
* [Crawl4AI](https://github.com/unclecode/crawl4ai) - Web crawling
* [Qwen API](https://dashscope.aliyuncs.com/) - Embeddings
* [ChromaDB](https://www.trychroma.com/) - Vector database
* [Streamlit](https://streamlit.io/) - Frontend

---

## ğŸ› ï¸ Troubleshooting

* **Crawl4AI fails** â†’ Some sites block bots. Try adding headers, delays, or testing another site.
* **Qwen API 404** â†’ Ensure your API key is valid and endpoint is correct.
* **Chroma dimension mismatch** â†’ Clear database if embedding dimensions changed.
* **Empty JSON** â†’ The site may be heavily JavaScript-based; try alternate scraping config.

---

## ğŸ“œ License

MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Arun Mandava**
